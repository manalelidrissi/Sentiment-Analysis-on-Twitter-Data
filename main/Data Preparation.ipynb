{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35020759",
   "metadata": {},
   "source": [
    "***\n",
    "# <h1 align = 'center'>Data preprocessing</h1> \n",
    "#### <center> Abderahmane BELLAMINE, Manal EL IDRISSI </center>\n",
    "#### <center> Ecole Centrale Casablanca </center>\n",
    "#### <center> January 2021 </center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2efa1",
   "metadata": {},
   "source": [
    "The purpose of this Lab is to clean data previously collected from Twitter using regex and some nlp techniques ( tokenization, stemmatizatiob). This data will be used for visualization and the creation of Bokeh app. \n",
    "\n",
    "### Objectives of this jupyter notebooks file:\n",
    "- Data Preparation and Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4d017",
   "metadata": {},
   "source": [
    "#### Dependencies import\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821cca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38975b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    data = list()\n",
    "    with open(fname, 'r') as file:\n",
    "        for line in file:\n",
    "            data += json.loads(line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2faec018",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_tweets = load_data(\"../data/usa_tweets.jsonl\")\n",
    "df_usa = pd.DataFrame(usa_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6215f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_tweets = load_data(\"../data/uk_tweets.jsonl\")\n",
    "df_uk = pd.DataFrame(uk_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0dcb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "germany_tweets = load_data(\"../data/germany_tweets.jsonl\")\n",
    "df_germany = pd.DataFrame(germany_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b480968",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee498c",
   "metadata": {},
   "source": [
    "In this section, we will use the data we stored and perform some text mining tasks on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90f1cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    user_handles = re.findall(r'@[A-Za-z0-9]+', tweet) #search @mentions\n",
    "    hashtags = re.findall(r'#[A-Za-z0-9]+', tweet) #search #hashtags\n",
    "    links = re.findall(r' https?:\\/\\/\\S*', tweet) #search hyperlinks\n",
    "    \n",
    "    cleaned_tweet = re.sub(r'@[A-Za-z0-9]+','', tweet) #remove @mentions\n",
    "    cleaned_tweet = re.sub(r'#[A-Za-z0-9]+', '', cleaned_tweet) #remove #hashtags \n",
    "    cleaned_tweet = re.sub(r' https?:\\/\\/\\S*', '', cleaned_tweet, flags=re.MULTILINE) #remove hyperlinks\n",
    "    return cleaned_tweet.strip(), user_handles, hashtags, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcbbcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a small test\n",
    "example1=\"Digital X Worldwide | Today Is Steve Jobs Day In California @apple http://t.co/QSCHuMIN\"\n",
    "example2=\"Wow. Great deals on refurbed #iPad (first gen) models. RT: Apple offers great deals on refurbished 1st-gen iPads http://t.co/ukWOKBGd @Apple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb1cceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Digital X Worldwide | Today Is Steve Jobs Day In California', ['@apple'], [], [' http://t.co/QSCHuMIN'])\n",
      "('Wow. Great deals on refurbed  (first gen) models. RT: Apple offers great deals on refurbished 1st-gen iPads', ['@Apple'], ['#iPad'], [' http://t.co/ukWOKBGd'])\n"
     ]
    }
   ],
   "source": [
    "print(clean_tweet(example1))\n",
    "# ('Digital X Worldwide | Today Is Steve Jobs Day In California', ['@apple'], [], ['http://t.co/QSCHuMIN'])\n",
    "print(clean_tweet(example2))\n",
    "# ('Wow. Great deals on refurbed  (first gen) models. RT: Apple offers great deals on refurbished 1st-gen iPads', ['@Apple'], ['#iPad'], ['http://t.co/ukWOKBGd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b612cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_tweets(df):\n",
    "    df['cleaned_tweet'] = df['text'].apply(lambda x: clean_tweet(x)[0])\n",
    "    df['user_handles'] = df['text'].apply(lambda x: clean_tweet(x)[1])\n",
    "    df['hashtags'] = df['text'].apply(lambda x: clean_tweet(x)[2])\n",
    "    df['links'] = df['text'].apply(lambda x: clean_tweet(x)[3])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "816a2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0‚Äì9]+','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddd92974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    '''\n",
    "    Function that takes a text, tokenizes it using spacy's nlp(text), processes that text in spaCy and appends the results to a list \n",
    "    Return: list of tokens\n",
    "    '''\n",
    "    # write your code\n",
    "    list_tokens = list()\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        list_tokens.append(token)\n",
    "    return list_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e433a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35c1b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b05042de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First twenty stop words: ['because', 'none', 'otherwise', 'fifteen', 'get', 'everyone', 'would', 'us', 'also', 'alone', 'after', 'unless', '‚Äôm', 'thence', 'eleven', 'at', 'whatever', '‚Äôre', 'others', 'seem']\n"
     ]
    }
   ],
   "source": [
    "# The total number of stop words:\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "\n",
    "# The first ten stop words:\n",
    "print('First twenty stop words: %s' % list(spacy_stopwords)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "827fde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_noStopw(text):\n",
    "    '''\n",
    "    Function that takes a text, tokenizes it using spacy's nlp function, removes the stopwords \n",
    "    Return: list of filtered tokens\n",
    "    '''\n",
    "    # write your code\n",
    "    list_tokens = list()\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_stop == False:\n",
    "            list_tokens.append(token.text)\n",
    "    return list_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a4bbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c5d1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b31c6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(df):\n",
    "    \n",
    "    df = clean_all_tweets(df)\n",
    "    df['punct'] = df.cleaned_tweet.apply(remove_punct)\n",
    "    df['tokenized_text'] = df.punct.apply(tokenizer)\n",
    "    df['tokenizer_noStopw'] = df.punct.apply(tokenizer_noStopw)\n",
    "    df['stemmed_text'] = df.tokenizer_noStopw.apply(stemming)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6d843a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>twitter_name</th>\n",
       "      <th>text</th>\n",
       "      <th>number_of_likes</th>\n",
       "      <th>number_of_retweets</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>user_handles</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>links</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tokenizer_noStopw</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1643812291000</td>\n",
       "      <td>Grant Rivers üè≥Ô∏è‚Äçüåà</td>\n",
       "      <td>SnowAndBeach</td>\n",
       "      <td>In addition‚Ä¶\\n\\nChildren over the age of 12 ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In addition‚Ä¶\\n\\nChildren over the age of 12 ar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ https://t.co/AZnsErX4lR]</td>\n",
       "      <td>In addition‚Ä¶\\n\\nChildren over the age of 12 ar...</td>\n",
       "      <td>[In, addition, ‚Ä¶, \\n\\n, Children, over, the, a...</td>\n",
       "      <td>[addition, ‚Ä¶, \\n\\n, Children, age, 12, able, e...</td>\n",
       "      <td>addit ‚Ä¶ \\n\\n children age 12 abl enter countri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1643812282000</td>\n",
       "      <td>NFTurk (L-Constant Panic)</td>\n",
       "      <td>MichaelTurk</td>\n",
       "      <td>#covid should be like the perfect attendance a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>should be like the perfect attendance award in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#covid, #US]</td>\n",
       "      <td>[ https://t.co/hKiM3oTffw]</td>\n",
       "      <td>should be like the perfect attendance award in...</td>\n",
       "      <td>[should, be, like, the, perfect, attendance, a...</td>\n",
       "      <td>[like, perfect, attendance, award, high, schoo...</td>\n",
       "      <td>like perfect attend award high school person  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1643812202000</td>\n",
       "      <td>Gate 15</td>\n",
       "      <td>Gate_15_Analyst</td>\n",
       "      <td>As anti-vaccine mandate protest enters 5th day...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>As anti-vaccine mandate protest enters 5th day...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#COVID]</td>\n",
       "      <td>[ https://t.co/rbRYVYF29P]</td>\n",
       "      <td>As antivaccine mandate protest enters 5th day ...</td>\n",
       "      <td>[As, antivaccine, mandate, protest, enters, 5t...</td>\n",
       "      <td>[antivaccine, mandate, protest, enters, 5th, d...</td>\n",
       "      <td>antivaccin mandat protest enter 5th day ottawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1643812183000</td>\n",
       "      <td>Gate 15</td>\n",
       "      <td>Gate_15_Analyst</td>\n",
       "      <td>Ottawa's police chief says the response to the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ottawa's police chief says the response to the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#COVID]</td>\n",
       "      <td>[ https://t.co/ScmVUAUfYJ]</td>\n",
       "      <td>Ottawas police chief says the response to the ...</td>\n",
       "      <td>[Ottawas, police, chief, says, the, response, ...</td>\n",
       "      <td>[Ottawas, police, chief, says, response, prote...</td>\n",
       "      <td>ottawa polic chief say respons protest success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643812175000</td>\n",
       "      <td>Gate 15</td>\n",
       "      <td>Gate_15_Analyst</td>\n",
       "      <td>COVID study in which young adults were infecte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID study in which young adults were infecte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#COVID]</td>\n",
       "      <td>[ https://t.co/B7krPeoSaX]</td>\n",
       "      <td>COVID study in which young adults were infecte...</td>\n",
       "      <td>[COVID, study, in, which, young, adults, were,...</td>\n",
       "      <td>[COVID, study, young, adults, infected, virus,...</td>\n",
       "      <td>covid studi young adult infect viru reveal result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                     author     twitter_name  \\\n",
       "0  1643812291000          Grant Rivers üè≥Ô∏è‚Äçüåà     SnowAndBeach   \n",
       "1  1643812282000  NFTurk (L-Constant Panic)      MichaelTurk   \n",
       "2  1643812202000                    Gate 15  Gate_15_Analyst   \n",
       "3  1643812183000                    Gate 15  Gate_15_Analyst   \n",
       "4  1643812175000                    Gate 15  Gate_15_Analyst   \n",
       "\n",
       "                                                text  number_of_likes  \\\n",
       "0  In addition‚Ä¶\\n\\nChildren over the age of 12 ar...                0   \n",
       "1  #covid should be like the perfect attendance a...                0   \n",
       "2  As anti-vaccine mandate protest enters 5th day...                0   \n",
       "3  Ottawa's police chief says the response to the...                0   \n",
       "4  COVID study in which young adults were infecte...                0   \n",
       "\n",
       "   number_of_retweets                                      cleaned_tweet  \\\n",
       "0                   0  In addition‚Ä¶\\n\\nChildren over the age of 12 ar...   \n",
       "1                   0  should be like the perfect attendance award in...   \n",
       "2                   0  As anti-vaccine mandate protest enters 5th day...   \n",
       "3                   0  Ottawa's police chief says the response to the...   \n",
       "4                   0  COVID study in which young adults were infecte...   \n",
       "\n",
       "  user_handles       hashtags                       links  \\\n",
       "0           []             []  [ https://t.co/AZnsErX4lR]   \n",
       "1           []  [#covid, #US]  [ https://t.co/hKiM3oTffw]   \n",
       "2           []       [#COVID]  [ https://t.co/rbRYVYF29P]   \n",
       "3           []       [#COVID]  [ https://t.co/ScmVUAUfYJ]   \n",
       "4           []       [#COVID]  [ https://t.co/B7krPeoSaX]   \n",
       "\n",
       "                                               punct  \\\n",
       "0  In addition‚Ä¶\\n\\nChildren over the age of 12 ar...   \n",
       "1  should be like the perfect attendance award in...   \n",
       "2  As antivaccine mandate protest enters 5th day ...   \n",
       "3  Ottawas police chief says the response to the ...   \n",
       "4  COVID study in which young adults were infecte...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [In, addition, ‚Ä¶, \\n\\n, Children, over, the, a...   \n",
       "1  [should, be, like, the, perfect, attendance, a...   \n",
       "2  [As, antivaccine, mandate, protest, enters, 5t...   \n",
       "3  [Ottawas, police, chief, says, the, response, ...   \n",
       "4  [COVID, study, in, which, young, adults, were,...   \n",
       "\n",
       "                                   tokenizer_noStopw  \\\n",
       "0  [addition, ‚Ä¶, \\n\\n, Children, age, 12, able, e...   \n",
       "1  [like, perfect, attendance, award, high, schoo...   \n",
       "2  [antivaccine, mandate, protest, enters, 5th, d...   \n",
       "3  [Ottawas, police, chief, says, response, prote...   \n",
       "4  [COVID, study, young, adults, infected, virus,...   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  addit ‚Ä¶ \\n\\n children age 12 abl enter countri...  \n",
       "1  like perfect attend award high school person  ...  \n",
       "2  antivaccin mandat protest enter 5th day ottawa...  \n",
       "3  ottawa polic chief say respons protest success...  \n",
       "4  covid studi young adult infect viru reveal result  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the head of your Dataframe\n",
    "new_df_usa = build_dataframe(df_usa)\n",
    "new_df_usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf16c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>twitter_name</th>\n",
       "      <th>text</th>\n",
       "      <th>number_of_likes</th>\n",
       "      <th>number_of_retweets</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>user_handles</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>links</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tokenizer_noStopw</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1643812310000</td>\n",
       "      <td>Thomas (Tom) Yoritaka</td>\n",
       "      <td>tomyoritaka</td>\n",
       "      <td>God-given #science - plus consideration for fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>God-given  - plus consideration for fellow cit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#science]</td>\n",
       "      <td>[ https://t.co/Vjqaz8LCJV]</td>\n",
       "      <td>Godgiven   plus consideration for fellow citiz...</td>\n",
       "      <td>[Godgiven,   , plus, consideration, for, fello...</td>\n",
       "      <td>[Godgiven,   , plus, consideration, fellow, ci...</td>\n",
       "      <td>godgiven    plu consider fellow citizen   save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1643812260000</td>\n",
       "      <td>CartoonStock</td>\n",
       "      <td>CartoonStock</td>\n",
       "      <td>\"We're running low so some of you will have to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"We're running low so some of you will have to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ https://t.co/3iVlWv71F5]</td>\n",
       "      <td>Were running low so some of you will have to s...</td>\n",
       "      <td>[Were, running, low, so, some, of, you, will, ...</td>\n",
       "      <td>[running, low, share, \\n\\n, Cartoon, Jeremy, B...</td>\n",
       "      <td>run low share \\n\\n cartoon jeremi banx \\n\\n fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1643812159000</td>\n",
       "      <td>Gary #NHSPay15 üíôüåçüåàüíñ</td>\n",
       "      <td>GarySyms</td>\n",
       "      <td>@benonwine Yep, me &amp;amp; my Husband 3√ó jabbed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yep, me &amp;amp; my Husband 3√ó jabbed still  , ha...</td>\n",
       "      <td>[@benonwine]</td>\n",
       "      <td>[#WearAMask]</td>\n",
       "      <td>[ https://t.co/Ik8Tqzy8pH]</td>\n",
       "      <td>Yep me amp my Husband 3√ó jabbed still   hand s...</td>\n",
       "      <td>[Yep, me, amp, my, Husband, 3√ó, jabbed, still,...</td>\n",
       "      <td>[Yep, amp, Husband, 3√ó, jabbed,   , hand, sani...</td>\n",
       "      <td>yep amp husband 3√ó jab    hand sanit lft touch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1643812147000</td>\n",
       "      <td>Ed Kiernan</td>\n",
       "      <td>Eddie_K_1974</td>\n",
       "      <td>#BorisJohnson announced he will end the #Covid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>announced he will end the  pandemic by no long...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#BorisJohnson, #Covid]</td>\n",
       "      <td>[ https://t.co/j13sTKZCO2]</td>\n",
       "      <td>announced he will end the  pandemic by no long...</td>\n",
       "      <td>[announced, he, will, end, the,  , pandemic, b...</td>\n",
       "      <td>[announced, end,  , pandemic, longer, publishi...</td>\n",
       "      <td>announc end   pandem longer publish figur numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643812146000</td>\n",
       "      <td>Doffou Radio Bordeaux</td>\n",
       "      <td>DoffouRadio</td>\n",
       "      <td>#NowPlaying Lauryn Hill - Doo Wop (That Thing)...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lauryn Hill - Doo Wop (That Thing)       ‚Ä¶</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#NowPlaying, #radioking, #bokaomw, #doffourad...</td>\n",
       "      <td>[ https://t.co/pRsqhj4lFu]</td>\n",
       "      <td>Lauryn Hill  Doo Wop That Thing       ‚Ä¶</td>\n",
       "      <td>[Lauryn, Hill,  , Doo, Wop, That, Thing,      ...</td>\n",
       "      <td>[Lauryn, Hill,  , Doo, Wop, Thing,       , ‚Ä¶]</td>\n",
       "      <td>lauryn hill   doo wop thing        ‚Ä¶</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                 author  twitter_name  \\\n",
       "0  1643812310000  Thomas (Tom) Yoritaka   tomyoritaka   \n",
       "1  1643812260000           CartoonStock  CartoonStock   \n",
       "2  1643812159000    Gary #NHSPay15 üíôüåçüåàüíñ      GarySyms   \n",
       "3  1643812147000             Ed Kiernan  Eddie_K_1974   \n",
       "4  1643812146000  Doffou Radio Bordeaux   DoffouRadio   \n",
       "\n",
       "                                                text  number_of_likes  \\\n",
       "0  God-given #science - plus consideration for fe...                0   \n",
       "1  \"We're running low so some of you will have to...                0   \n",
       "2  @benonwine Yep, me &amp; my Husband 3√ó jabbed ...                0   \n",
       "3  #BorisJohnson announced he will end the #Covid...                0   \n",
       "4  #NowPlaying Lauryn Hill - Doo Wop (That Thing)...                0   \n",
       "\n",
       "   number_of_retweets                                      cleaned_tweet  \\\n",
       "0                   0  God-given  - plus consideration for fellow cit...   \n",
       "1                   0  \"We're running low so some of you will have to...   \n",
       "2                   0  Yep, me &amp; my Husband 3√ó jabbed still  , ha...   \n",
       "3                   0  announced he will end the  pandemic by no long...   \n",
       "4                   0         Lauryn Hill - Doo Wop (That Thing)       ‚Ä¶   \n",
       "\n",
       "   user_handles                                           hashtags  \\\n",
       "0            []                                         [#science]   \n",
       "1            []                                                 []   \n",
       "2  [@benonwine]                                       [#WearAMask]   \n",
       "3            []                            [#BorisJohnson, #Covid]   \n",
       "4            []  [#NowPlaying, #radioking, #bokaomw, #doffourad...   \n",
       "\n",
       "                        links  \\\n",
       "0  [ https://t.co/Vjqaz8LCJV]   \n",
       "1  [ https://t.co/3iVlWv71F5]   \n",
       "2  [ https://t.co/Ik8Tqzy8pH]   \n",
       "3  [ https://t.co/j13sTKZCO2]   \n",
       "4  [ https://t.co/pRsqhj4lFu]   \n",
       "\n",
       "                                               punct  \\\n",
       "0  Godgiven   plus consideration for fellow citiz...   \n",
       "1  Were running low so some of you will have to s...   \n",
       "2  Yep me amp my Husband 3√ó jabbed still   hand s...   \n",
       "3  announced he will end the  pandemic by no long...   \n",
       "4            Lauryn Hill  Doo Wop That Thing       ‚Ä¶   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Godgiven,   , plus, consideration, for, fello...   \n",
       "1  [Were, running, low, so, some, of, you, will, ...   \n",
       "2  [Yep, me, amp, my, Husband, 3√ó, jabbed, still,...   \n",
       "3  [announced, he, will, end, the,  , pandemic, b...   \n",
       "4  [Lauryn, Hill,  , Doo, Wop, That, Thing,      ...   \n",
       "\n",
       "                                   tokenizer_noStopw  \\\n",
       "0  [Godgiven,   , plus, consideration, fellow, ci...   \n",
       "1  [running, low, share, \\n\\n, Cartoon, Jeremy, B...   \n",
       "2  [Yep, amp, Husband, 3√ó, jabbed,   , hand, sani...   \n",
       "3  [announced, end,  , pandemic, longer, publishi...   \n",
       "4      [Lauryn, Hill,  , Doo, Wop, Thing,       , ‚Ä¶]   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  godgiven    plu consider fellow citizen   save...  \n",
       "1  run low share \\n\\n cartoon jeremi banx \\n\\n fi...  \n",
       "2  yep amp husband 3√ó jab    hand sanit lft touch...  \n",
       "3  announc end   pandem longer publish figur numb...  \n",
       "4               lauryn hill   doo wop thing        ‚Ä¶  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_uk = build_dataframe(df_uk)\n",
    "new_df_uk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "359b0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>twitter_name</th>\n",
       "      <th>text</th>\n",
       "      <th>number_of_likes</th>\n",
       "      <th>number_of_retweets</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>user_handles</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>links</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tokenizer_noStopw</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1643812310000</td>\n",
       "      <td>Thomas (Tom) Yoritaka</td>\n",
       "      <td>tomyoritaka</td>\n",
       "      <td>God-given #science - plus consideration for fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>God-given  - plus consideration for fellow cit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#science]</td>\n",
       "      <td>[ https://t.co/Vjqaz8LCJV]</td>\n",
       "      <td>Godgiven   plus consideration for fellow citiz...</td>\n",
       "      <td>[Godgiven,   , plus, consideration, for, fello...</td>\n",
       "      <td>[Godgiven,   , plus, consideration, fellow, ci...</td>\n",
       "      <td>godgiven    plu consider fellow citizen   save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1643812260000</td>\n",
       "      <td>CartoonStock</td>\n",
       "      <td>CartoonStock</td>\n",
       "      <td>\"We're running low so some of you will have to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"We're running low so some of you will have to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ https://t.co/3iVlWv71F5]</td>\n",
       "      <td>Were running low so some of you will have to s...</td>\n",
       "      <td>[Were, running, low, so, some, of, you, will, ...</td>\n",
       "      <td>[running, low, share, \\n\\n, Cartoon, Jeremy, B...</td>\n",
       "      <td>run low share \\n\\n cartoon jeremi banx \\n\\n fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1643812159000</td>\n",
       "      <td>Gary #NHSPay15 üíôüåçüåàüíñ</td>\n",
       "      <td>GarySyms</td>\n",
       "      <td>@benonwine Yep, me &amp;amp; my Husband 3√ó jabbed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yep, me &amp;amp; my Husband 3√ó jabbed still  , ha...</td>\n",
       "      <td>[@benonwine]</td>\n",
       "      <td>[#WearAMask]</td>\n",
       "      <td>[ https://t.co/Ik8Tqzy8pH]</td>\n",
       "      <td>Yep me amp my Husband 3√ó jabbed still   hand s...</td>\n",
       "      <td>[Yep, me, amp, my, Husband, 3√ó, jabbed, still,...</td>\n",
       "      <td>[Yep, amp, Husband, 3√ó, jabbed,   , hand, sani...</td>\n",
       "      <td>yep amp husband 3√ó jab    hand sanit lft touch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1643812147000</td>\n",
       "      <td>Ed Kiernan</td>\n",
       "      <td>Eddie_K_1974</td>\n",
       "      <td>#BorisJohnson announced he will end the #Covid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>announced he will end the  pandemic by no long...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#BorisJohnson, #Covid]</td>\n",
       "      <td>[ https://t.co/j13sTKZCO2]</td>\n",
       "      <td>announced he will end the  pandemic by no long...</td>\n",
       "      <td>[announced, he, will, end, the,  , pandemic, b...</td>\n",
       "      <td>[announced, end,  , pandemic, longer, publishi...</td>\n",
       "      <td>announc end   pandem longer publish figur numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643812146000</td>\n",
       "      <td>Doffou Radio Bordeaux</td>\n",
       "      <td>DoffouRadio</td>\n",
       "      <td>#NowPlaying Lauryn Hill - Doo Wop (That Thing)...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lauryn Hill - Doo Wop (That Thing)       ‚Ä¶</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#NowPlaying, #radioking, #bokaomw, #doffourad...</td>\n",
       "      <td>[ https://t.co/pRsqhj4lFu]</td>\n",
       "      <td>Lauryn Hill  Doo Wop That Thing       ‚Ä¶</td>\n",
       "      <td>[Lauryn, Hill,  , Doo, Wop, That, Thing,      ...</td>\n",
       "      <td>[Lauryn, Hill,  , Doo, Wop, Thing,       , ‚Ä¶]</td>\n",
       "      <td>lauryn hill   doo wop thing        ‚Ä¶</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                 author  twitter_name  \\\n",
       "0  1643812310000  Thomas (Tom) Yoritaka   tomyoritaka   \n",
       "1  1643812260000           CartoonStock  CartoonStock   \n",
       "2  1643812159000    Gary #NHSPay15 üíôüåçüåàüíñ      GarySyms   \n",
       "3  1643812147000             Ed Kiernan  Eddie_K_1974   \n",
       "4  1643812146000  Doffou Radio Bordeaux   DoffouRadio   \n",
       "\n",
       "                                                text  number_of_likes  \\\n",
       "0  God-given #science - plus consideration for fe...                0   \n",
       "1  \"We're running low so some of you will have to...                0   \n",
       "2  @benonwine Yep, me &amp; my Husband 3√ó jabbed ...                0   \n",
       "3  #BorisJohnson announced he will end the #Covid...                0   \n",
       "4  #NowPlaying Lauryn Hill - Doo Wop (That Thing)...                0   \n",
       "\n",
       "   number_of_retweets                                      cleaned_tweet  \\\n",
       "0                   0  God-given  - plus consideration for fellow cit...   \n",
       "1                   0  \"We're running low so some of you will have to...   \n",
       "2                   0  Yep, me &amp; my Husband 3√ó jabbed still  , ha...   \n",
       "3                   0  announced he will end the  pandemic by no long...   \n",
       "4                   0         Lauryn Hill - Doo Wop (That Thing)       ‚Ä¶   \n",
       "\n",
       "   user_handles                                           hashtags  \\\n",
       "0            []                                         [#science]   \n",
       "1            []                                                 []   \n",
       "2  [@benonwine]                                       [#WearAMask]   \n",
       "3            []                            [#BorisJohnson, #Covid]   \n",
       "4            []  [#NowPlaying, #radioking, #bokaomw, #doffourad...   \n",
       "\n",
       "                        links  \\\n",
       "0  [ https://t.co/Vjqaz8LCJV]   \n",
       "1  [ https://t.co/3iVlWv71F5]   \n",
       "2  [ https://t.co/Ik8Tqzy8pH]   \n",
       "3  [ https://t.co/j13sTKZCO2]   \n",
       "4  [ https://t.co/pRsqhj4lFu]   \n",
       "\n",
       "                                               punct  \\\n",
       "0  Godgiven   plus consideration for fellow citiz...   \n",
       "1  Were running low so some of you will have to s...   \n",
       "2  Yep me amp my Husband 3√ó jabbed still   hand s...   \n",
       "3  announced he will end the  pandemic by no long...   \n",
       "4            Lauryn Hill  Doo Wop That Thing       ‚Ä¶   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Godgiven,   , plus, consideration, for, fello...   \n",
       "1  [Were, running, low, so, some, of, you, will, ...   \n",
       "2  [Yep, me, amp, my, Husband, 3√ó, jabbed, still,...   \n",
       "3  [announced, he, will, end, the,  , pandemic, b...   \n",
       "4  [Lauryn, Hill,  , Doo, Wop, That, Thing,      ...   \n",
       "\n",
       "                                   tokenizer_noStopw  \\\n",
       "0  [Godgiven,   , plus, consideration, fellow, ci...   \n",
       "1  [running, low, share, \\n\\n, Cartoon, Jeremy, B...   \n",
       "2  [Yep, amp, Husband, 3√ó, jabbed,   , hand, sani...   \n",
       "3  [announced, end,  , pandemic, longer, publishi...   \n",
       "4      [Lauryn, Hill,  , Doo, Wop, Thing,       , ‚Ä¶]   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  godgiven    plu consider fellow citizen   save...  \n",
       "1  run low share \\n\\n cartoon jeremi banx \\n\\n fi...  \n",
       "2  yep amp husband 3√ó jab    hand sanit lft touch...  \n",
       "3  announc end   pandem longer publish figur numb...  \n",
       "4               lauryn hill   doo wop thing        ‚Ä¶  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_germany = build_dataframe(df_germany)\n",
    "new_df_germany.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32771074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d733a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_usa.to_csv(\"../cleaned_data/usa_cleaned_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dadc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_uk.to_csv(\"../cleaned_data/uk_cleaned_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d905782",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_germany.to_csv(\"../cleaned_data/germany_cleaned_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c56dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
